
# Initialization


```python
def createBoard():
    return np.zeros((6,7),dtype=int)
```


```python
def initializeNetworks(batchSize):
    networks = []
    for i in range(batchSize):
        
        model = models.Sequential()
        model.add(Dense(128,input_shape=(inputSize,)))
        model.add(Dense(128))
        model.add(Dense(outputSize,activation='linear'))
        model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
        
        networks.append(model)
    return networks
```

# Gameplay Logic


```python
def step(player, board, network, col):
    
    cont = True
    i = 5
    
    while cont == True:
        if i == -7:
            return False, board, col, i
        if board[i][col] == 0:
            board[i][col] = player
            cont = False
        else:
            i-=1
   
    return authenticate(board, player),board,col,i
```


```python
def authenticate(board, player):
    gameOver = False
    
    # search for horizontal win
    for i in range(board.shape[0]):
        row = board[i]
        for j in range(0,4):
            if [row[j],row[j+1],row[j+2],row[j+3]] == [player,player,player,player]:
                gameOver = True

    # search for vertical win
    for i in range(board.shape[1]):
        row = board.T[i]
        for j in range(0,3):
            if [row[j],row[j+1],row[j+2],row[j+3]] == [player,player,player,player]:
                gameOver = True

    # search for diagonal win
    for i in range(-2,4):
        diag = (np.diagonal(np.fliplr(board),i))
        for j in range(len(diag)-3):            
            if ([diag[j],diag[j+1],diag[j+2],diag[j+3]] == [player,player,player,player]):
                gameOver = True

    # search for diagonal win
    for i in range(-2,4):
        diag = (np.diagonal(board,i))
        for j in range(len(diag)-3):
            if ([diag[j],diag[j+1],diag[j+2],diag[j+3]] == [player,player,player,player]):
                gameOver = True
    
    return gameOver
```

# Replay Buffer


```python
def createGameplay(networks,games,memoryCount,memory,epsilon):
    record = np.zeros(2)
    
    # games per epoch
    for i in range(games):
        board = createBoard()
        
        # stores replay memory per game
        boards = np.zeros((inputSize+1,inputSize))
        players = np.zeros((inputSize+1))
        cols = np.zeros((inputSize+1))
                
        index= 0
        win = False
        tieGame = False
        while win == False:
            
            # player 1,2 play loop
            for player in range(1,3):
                try:
                    col = epsilonGreedy(epsilon,networks[player-1],board)
                    win,board,col,i = step(player,board,networks[player-1],col)
                    print(board)
                    # tie
                    if col == -1 or i == -7:
                        tieGame = True
                        break
                        
                except ValueError:
                    pass
                
                # append to replay memory
                boards[index] = board.reshape(inputSize)
                players[index] = player
                cols[index] = col
                index+=1
                
                # edit replay memory with new memories
                if win == True:
                    gameMemory = replayMemory(networks, boards, players, cols)
                    if memoryCount < memSize:
                        memory.append(gameMemory)
                    else:
                        memory[memoryCount % memSize] = gameMemory
                    memoryCount+=1
                    
                    break
            
            if tieGame == True:
                break

    return memoryCount, memory
```


```python
def epsilonGreedy(epsilon,network,board):
    # random value for epsilon-greedy
    rand = np.random.rand(1)[0]
    
    # decision based on rand
    if rand <= epsilon:
        
        full = getFull(board)
        if len(full) == outputSize:
            return -1
        
        available = []
        for i in range(outputSize):
            if i not in full:
                available.append(i)

        col = random.choice(available)
        
    else:
        col = np.argmax(throughNetwork(board,network))
    
    return col
```


```python
def replayMemory(networks, boards, players, cols):
    
    boardsA = []
    boardsB = []
    
    countA = 0
    countB = 0
    
    i = 0
    while np.sum(boards[i]) != 0:
        if players[i] == 1:
            boardsA.append(boards[i])
            countA+=1
            
        if players[i] == 2:
            boardsB.append(boards[i])
            countB+=1
            
        i+=1
    
#  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  #  # 
    
    tempTargetQ = np.zeros((i,outputSize))
    
    for j in range(i-1):
        full = getFull(boards[j].reshape(6,7))
        for k in range(outputSize):
            
            if k in full:
                tempTargetQ[j][k] = 0
                
            else:
                tempTargetQ[j][k] = np.max(throughNetwork(
                    step(int(players[j]), np.copy(boards[j+1]).reshape(6,7), networks[int(players[j]-1)], k)[1],
                    networks[int(players[j]-1)]))
    
    tempTargetQ[int(i-1)][int(cols[i-1])] = 100
    
    for j in range(outputSize):
        if j != cols[int(i-1)]:
            tempTargetQ[int(i-2)][j] = -100
    
    memoryA = []
    memoryB = []
    
    for j in range(i):
        if players[j] == 1:
            memoryA.append([boards[j],tempTargetQ[j]])
        if players[j] == 2:
            memoryB.append([boards[j],tempTargetQ[j]])
            
    gameMemory = [memoryA,memoryB]

    return gameMemory
```

# Neural Net Logic


```python
def getFull(board):
    
    # list of full/invalid columns
    full = []
    
    for i in range(outputSize):
        if np.sum(board.reshape(6,7).T[i] != 0) == 6:
            full.append(i)
    
    return full
```


```python
def throughNetwork(board, network):
    
    # reshaping board for network input
    inputBoard = board.reshape(inputSize)
    inputBoard = board.reshape(1,-1)
    
    # getting network prediction
    output = network.predict(inputBoard)[0]
    output[getFull(inputBoard)] = -10000
    print(output)
    return output
```


```python
def trainNetwork(networks, memory):
    
    # size of memory sample
    sampleSize = len(memory)//10
    memPerGamePerAgent = 2
    
    # creating sample memory arrays
    sampleStateMemoryA = np.zeros((memPerGamePerAgent * sampleSize,inputSize))
    sampleStateMemoryB = np.zeros((memPerGamePerAgent * sampleSize,inputSize))
    sampleTargetA = np.zeros((memPerGamePerAgent * sampleSize,outputSize))
    sampleTargetB = np.zeros((memPerGamePerAgent * sampleSize,outputSize))
    randomGames = np.array(random.sample(range(0,len(memory)),sampleSize))

    # memory stores games
    # memory[0] is the 0th game
    # memory[0][0] is the boards and targets for agent A in game 0
    # memory[0][0][0] is the board and target for agent A in game 0, move 0
    # memory[0][0][0][0] is the board for agent A in game 0, move 0
    
    for i in range(len(randomGames)):
        game = memory[randomGames[i]]
        minimum = min(len(game[0]),len(game[1]))
        randomMoves = np.array(random.sample(range(0,minimum),memPerGamePerAgent))
        
        for j in range(memPerGamePerAgent):
            k = (i * 2) + j
            sampleStateMemoryA[k] = game[0][randomMoves[j]][0] # This is Agent A
            sampleStateMemoryB[k] = game[1][randomMoves[j]][0] # This is Agent B
            sampleTargetA[k] = game[0][randomMoves[j]][1] # This is Agent A
            sampleTargetB[k] = game[1][randomMoves[j]][1] # This is Agent B
        
    # training network
    print("Player 1 Agent...")
    networks[0].fit(sampleStateMemoryA,sampleTargetA,batch_size=16,epochs=epochs)
    print("Player 2 Agent...")
    networks[1].fit(sampleStateMemoryB,sampleTargetB,batch_size=16,epochs=epochs)
```

# Main Function


```python
import pandas as pd
import numpy as np
import random
import time

from keras import models
from keras import layers
from keras.layers import Dense, Activation
from keras.models import model_from_json
```


```python
inputSize = 42
outputSize = 7
memSize = 2000
batchSize = 2

# memory stored by games
memory = []

memoryCount = 0
```


```python
networks = initializeNetworks(batchSize)
epsilon = 1
```


```python
epsilon = 0.01
minEpsilon = 0.01
epsilonDecay = 0.0005

# iterations determind by epsilon decay rate
iterations = int((epsilon - minEpsilon) // epsilonDecay)
iterations = 1
epochs = 0
games = 1

# timer
startTime = time.time()

# loop through training
for iteration in range(iterations):
    iterationStartTime = time.time()
    print("\nITERATION:", iteration,"out of",iterations)
    
    # create gameplay, epsilon decay, and training
    memoryCount,memory = createGameplay(networks,games,memoryCount,memory,epsilon)
    if epsilon > minEpsilon:
        epsilon-=epsilonDecay
    trainNetwork(networks,memory)
    
    # stats display every 5 iterations
    printStats(5,memoryCount,epsilon,iterationStartTime,iteration,iterations)
    
    # after initial x games we only want y games per iteration to reduce training time yet start with efficient training data
    # games = 20
```

    
    ITERATION: 0 out of 1
    [-20.488363 -21.690168 -25.026758 -23.845098 -23.336388 -23.720821
     -20.481451]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 1]]
    [36.050625 37.741276 35.78969  40.888767 31.351141 32.170723 31.729376]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 2 0 0 1]]
    [-19.872581 -19.69345  -22.774624 -20.86695  -20.98074  -21.363949
     -19.698576]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 1 0 2 0 0 1]]
    [41.1325   36.74289  37.55422  40.824493 36.41214  32.954723 36.90776 ]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [2 1 0 2 0 0 1]]
    [-21.423803 -20.630043 -23.314646 -20.475176 -22.229187 -20.49828
     -21.95512 ]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [36.825417 33.137962 32.327477 38.2413   31.466194 29.07203  32.484146]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 2 0 0 0]
     [0 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [-24.420507 -27.923103 -30.375938 -18.68429  -28.407127 -26.952797
     -25.804892]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 1 0 0 0]
     [0 0 0 2 0 0 0]
     [0 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [42.70216  33.511333 36.29947  37.849064 35.78872  32.983406 34.256706]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 1 0 0 0]
     [0 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [-22.028645 -27.415785 -30.09106  -26.916079 -28.31897  -26.206268
     -27.983952]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [0 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [46.92074  29.83525  35.090794 34.301254 35.897934 30.08746  32.879444]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 0 1]]
    [-23.666359 -20.301508 -25.456831 -19.458792 -21.703426 -18.622269
     -20.578983]
    [[0 0 0 0 0 0 0]
     [0 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 1 1]]
    [44.800503 28.140442 31.313566 31.440277 29.489632 33.678883 28.712215]
    [[0 0 0 0 0 0 0]
     [2 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 1 1]]
    [-16.130138 -27.670225 -32.884037 -23.736553 -29.070164 -28.295734
     -25.719843]
    [[1 0 0 0 0 0 0]
     [2 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 0 0]
     [2 1 0 2 0 1 1]]
    [-10000.           25.261745     26.895288     26.2303       24.457315
         32.638226     28.526724]
    [[1 0 0 0 0 0 0]
     [2 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 0 0]
     [2 0 0 1 0 2 0]
     [2 1 0 2 0 1 1]]
    [-10000.          -36.689175    -37.399628    -33.449986    -40.13107
        -31.409946    -35.39101 ]
    [[1 0 0 0 0 0 0]
     [2 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 0]
     [2 1 0 2 0 1 1]]
    [-10000.           26.87545      31.141176     28.389782     27.952435
         37.718365     28.15006 ]
    [[1 0 0 0 0 0 0]
     [2 0 0 0 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 0]
     [2 1 0 2 0 1 1]]
    [-10000.          -31.820564    -34.448875    -28.136509    -32.75376
        -37.230457    -30.390184]
    [[1 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 0]
     [2 1 0 2 0 1 1]]
    [-10000.           23.775425     26.001364     18.09011      19.562906
         24.02213      22.48058 ]
    [[1 0 0 0 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 0]
     [2 1 2 2 0 1 1]]
    [-10000.          -42.771664    -38.75169     -33.686115    -43.884766
        -47.638596    -39.45326 ]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 0]
     [2 1 2 2 0 1 1]]
    [-1.0000000e+04  1.0167974e+01  1.8408123e+01 -1.0000000e+04
      9.3112278e+00  1.7553471e+01  1.9437597e+01]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 0]
     [2 0 0 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.          -46.673008    -40.933743 -10000.          -46.41299
        -52.561775    -40.678055]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 0]
     [1 0 0 2 0 1 1]
     [2 0 0 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-1.0000000e+04 -1.0120194e+01 -4.8058355e-01 -1.0000000e+04
     -8.5829687e+00 -2.1893346e-01  1.6300617e+01]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 2]
     [1 0 0 2 0 1 1]
     [2 0 0 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.          -37.09878     -32.100327 -10000.          -37.887276
        -43.68998     -42.92231 ]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 0]
     [2 0 0 1 0 2 2]
     [1 0 0 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-1.0000000e+04  5.6509886e+00  1.7163340e+01 -1.0000000e+04
      2.9118299e+00  1.0290347e+01  2.1807573e+01]
    [[1 0 0 1 0 0 0]
     [2 0 0 1 0 0 2]
     [2 0 0 1 0 2 2]
     [1 0 0 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.          -49.08898     -37.66214  -10000.          -50.279396
        -54.218204    -22.815407]
    [[1 0 0 1 0 0 1]
     [2 0 0 1 0 0 2]
     [2 0 0 1 0 2 2]
     [1 0 0 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.           11.85657      23.091175 -10000.           10.310035
         17.423782 -10000.      ]
    [[1 0 0 1 0 0 1]
     [2 0 0 1 0 0 2]
     [2 0 0 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.          -53.508568    -42.83731  -10000.          -53.22049
        -59.77386  -10000.      ]
    [[1 0 0 1 0 0 1]
     [2 0 0 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.            12.5346985     26.818047  -10000.
         12.353327      16.416721  -10000.       ]
    [[1 0 0 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.          -60.028286    -32.48814  -10000.          -58.98158
        -66.905235 -10000.      ]
    [[1 0 1 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 0 1 1]]
    [-10000.            13.410868  -10000.        -10000.
         15.5271015     13.98957   -10000.       ]
    [[1 0 1 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 0 2 2]
     [2 1 2 2 2 1 1]]
    [-10000.          -71.201904 -10000.       -10000.          -66.953224
        -79.531586 -10000.      ]
    [[1 0 1 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 0 1 1]
     [2 0 1 1 1 2 2]
     [2 1 2 2 2 1 1]]
    [-1.0000000e+04  2.0277481e+00 -1.0000000e+04 -1.0000000e+04
      1.7654076e+01  5.6817946e+00 -1.0000000e+04]
    [[1 0 1 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 0 2 2]
     [1 0 2 2 2 1 1]
     [2 0 1 1 1 2 2]
     [2 1 2 2 2 1 1]]
    [-10000.         -79.62094 -10000.      -10000.         -70.51386
        -85.94676 -10000.     ]
    [[1 0 1 1 0 0 1]
     [2 0 2 1 0 0 2]
     [2 0 1 1 1 2 2]
     [1 0 2 2 2 1 1]
     [2 0 1 1 1 2 2]
     [2 1 2 2 2 1 1]]
    [-19.469402 -18.951218 -21.73884  -19.378632 -20.649378 -19.972496
     -19.291014]
    [-22.23016  -22.11451  -25.386213 -23.451805 -22.891907 -23.281185
     -22.770243]
    [-23.07245  -24.415724 -24.680159 -24.30631  -25.60796  -25.512531
     -22.870169]
    [-20.966106 -20.940533 -24.601713 -22.365488 -21.977549 -22.43192
     -20.932245]
    [-23.28693  -22.989733 -25.372284 -23.61114  -22.591707 -25.719631
     -22.875385]
    [-21.313576 -22.945919 -25.092072 -23.698261 -24.575415 -23.304848
     -21.548174]
    [-20.6503   -20.233034 -22.690962 -21.425634 -21.445513 -21.755348
     -18.970549]
    [39.07743  33.947956 33.831116 38.574707 33.578266 30.750114 33.776863]
    [35.483456 42.900986 27.822794 32.989094 28.825806 23.102722 28.483782]
    [36.206566 29.3018   37.45588  32.44644  28.489681 29.479141 34.972725]
    [36.628464 35.122902 34.54695  40.157677 32.18799  29.598549 34.322327]
    [33.044643 25.32735  27.820919 32.030148 37.543736 22.800938 29.158195]
    [38.651714 26.930912 30.438713 32.220222 26.856092 36.032295 31.030752]
    [33.438232 25.617123 27.457447 33.338932 28.017483 22.639523 35.927147]
    [-20.388771 -21.30051  -23.384293 -21.504614 -23.174006 -21.195728
     -22.872772]
    [-22.786592 -19.045391 -23.770685 -21.45091  -22.847996 -22.138767
     -22.937891]
    [-24.623674 -25.35232  -25.220179 -23.91454  -26.856407 -24.646862
     -25.12671 ]
    [-22.517328 -21.877129 -25.141733 -21.973715 -23.225996 -21.566254
     -23.18879 ]
    [-24.838152 -23.926329 -25.912304 -23.21937  -23.840157 -24.853962
     -25.131931]
    [-22.8648   -23.882513 -25.63209  -23.306494 -25.82386  -22.439182
     -23.804718]
    [-22.201523 -21.169628 -23.230982 -21.033861 -22.693958 -20.889679
     -21.22709 ]
    [37.63009  31.905552 32.55543  36.240433 32.20764  29.821873 31.13421 ]
    [31.176378 39.296047 22.596048 30.4059   23.879858 19.220028 24.06016 ]
    [31.899485 25.696865 32.229137 29.863243 23.543734 25.596447 30.549107]
    [43.227448 35.95774  38.883503 35.32014  36.57942  34.148148 34.87645 ]
    [28.737566 21.72242  22.594177 29.446949 32.59779  18.918243 24.734577]
    [34.344627 23.325977 25.211971 29.637032 21.910147 32.1496   26.607141]
    [29.131153 22.012188 22.2307   30.755737 23.071531 18.756828 31.503532]
    [-23.385477 -28.593569 -30.445587 -19.713726 -29.35195  -27.650242
     -26.722538]
    [-25.783295 -26.33845  -30.83198  -19.660025 -29.025936 -28.593285
     -26.787659]
    [-27.62038  -32.645374 -32.281475 -22.123655 -33.03435  -31.10138
     -28.976479]
    [-24.09871  -26.074854 -29.951765 -24.857206 -26.429329 -24.81137
     -26.14865 ]
    [-27.834856 -31.219385 -32.9736   -21.428486 -30.018095 -31.30848
     -28.981697]
    [-25.861502 -31.175568 -32.69339  -21.515606 -32.001804 -28.8937
     -27.654484]
    [-25.198225 -28.462683 -30.292274 -19.242977 -28.871902 -27.344196
     -25.076857]
    [43.506832 32.27893  36.527428 35.848198 36.530167 33.73325  32.906776]
    [37.05312  39.669426 26.568045 30.013672 28.202383 23.131409 25.832722]
    [37.77622  26.07024  36.201134 29.471016 27.866259 29.507824 32.321667]
    [38.27883  36.089996 36.22388  31.867722 32.93258  28.70338  30.755451]
    [34.614304 22.095798 26.566168 29.054722 36.92031  22.82962  26.50714 ]
    [40.221367 23.699356 29.183968 29.2448   26.23267  36.060978 28.379702]
    [35.007893 22.38557  26.202696 30.363506 27.394058 22.668205 33.2761  ]
    [-23.406693 -28.775223 -31.763262 -28.245028 -29.41844  -27.274399
     -28.872713]
    [-23.391434 -25.831135 -30.547104 -27.891817 -28.93778  -27.84676
     -28.96672 ]
    [-25.228518 -32.138065 -31.996595 -30.355444 -32.946198 -30.354855
     -31.155544]
    [-23.5903   -28.922346 -30.58281  -25.586956 -30.19553  -28.317234
     -30.703844]
    [-25.442997 -30.712076 -32.688725 -29.660275 -29.929941 -30.561947
     -31.160759]
    [-23.46964  -30.668259 -32.408512 -29.747395 -31.913647 -28.147167
     -29.833548]
    [-22.806364 -27.955372 -30.007397 -27.474764 -28.783745 -26.597664
     -27.255922]
    [46.040897 33.04644  34.871323 35.742413 34.26766  32.140095 31.650723]
    [41.271698 35.993343 25.35937  26.465858 28.311592 20.235462 24.45546 ]
    [41.99481  22.394157 34.99246  25.923199 27.975471 26.611877 30.944407]
    [42.497414 32.41391  35.015205 28.319904 33.041786 25.807434 29.378191]
    [38.832882 18.419712 25.357498 25.506905 37.029526 19.933678 25.12988 ]
    [44.439957 20.02327  27.975288 25.696987 26.34188  33.165035 27.002438]
    [39.22648  18.709484 24.994022 26.81569  27.503271 19.772263 31.898832]
    [-19.177752 -22.35963  -28.011711 -20.182014 -23.589457 -22.488548
     -22.224617]
    [-25.029144 -18.716854 -25.912874 -20.434526 -22.322235 -20.262756
     -21.561752]
    [-26.866228 -25.023785 -27.362368 -22.898157 -26.330648 -22.770851
     -23.750574]
    [-25.22801  -21.80806  -25.948578 -18.12967  -23.579985 -20.73323
     -23.298872]
    [-27.080706 -23.597792 -28.054493 -22.202986 -23.314396 -22.977951
     -23.75579 ]
    [-25.107353 -23.553974 -27.774282 -22.290108 -25.2981   -20.563168
     -22.42858 ]
    [-24.444075 -20.841091 -25.37317  -20.017477 -22.1682   -19.013664
     -19.850954]
    [39.908855 28.766396 33.02362  29.83493  28.799942 35.160675 29.250711]
    [39.15146  34.29854  21.582138 23.604881 21.903297 23.826881 20.288233]
    [39.87457  20.699356 31.215223 23.062222 21.567175 30.203297 26.777178]
    [40.377182 30.719105 31.237974 25.458931 26.633493 29.398853 25.210964]
    [36.71265  16.724907 21.580261 22.645927 30.621227 23.525093 20.962646]
    [47.87597  29.894314 35.667454 32.898884 30.393559 38.309525 27.141138]
    [37.10624  17.014683 21.216793 23.954716 21.094973 23.363678 27.731602]
    [-10000.          -39.571884    -41.38707     -31.741064    -38.909096
        -37.492474    -31.767372]
    [-17.492928 -26.085573 -33.340076 -24.71229  -29.688974 -29.936226
     -26.702614]
    [-19.330008 -32.3925   -34.789566 -27.175917 -33.69739  -32.444317
     -28.891436]
    [-17.691792 -29.176779 -33.375782 -22.40743  -30.946722 -30.4067
     -28.439735]
    [-19.54449  -30.96651  -35.481697 -26.480747 -30.681133 -32.651417
     -28.896656]
    [-16.71309  -26.228874 -30.890312 -24.591013 -29.681149 -25.25447
     -27.531666]
    [-16.907856 -28.209808 -32.80037  -24.295237 -29.534939 -28.68713
     -24.991817]
    [-10000.           25.261745     26.895288     26.2303       24.457315
         32.638226     28.526724]
    [-10000.           31.419834     17.16386      18.394901     16.870975
         22.786224     20.102737]
    [-10000.           17.820648     26.796946     17.852242     16.534853
         29.162643     26.591684]
    [-10000.           27.840405     26.8197       20.248947     21.601173
         28.358196     25.025467]
    [-10000.           13.846206     17.161987     17.43595      25.58891
         22.48444      20.777155]
    [-10000.           27.015606     31.249178     27.6889       25.361238
         37.268867     26.955643]
    [-10000.           14.135978     16.798515     18.744732     16.062654
         22.323025     27.546108]
    [-10000.          -35.104527    -37.855667    -34.42572     -40.749878
        -33.050438    -36.373787]
    [-10000.          -41.41146     -39.305157    -36.88935     -44.75829
        -35.55853     -38.562603]
    [-10000.          -38.195736    -37.89137     -32.12086     -42.007633
        -33.520912    -38.1109  ]
    [-10000.          -39.985466    -39.997284    -36.19418     -41.74204
        -35.765636    -38.56782 ]
    [-10000.          -38.023052    -40.981388    -36.715633    -42.405922
        -35.13636     -38.23376 ]
    [-10000.          -37.228767    -37.31596     -34.00867     -40.595844
        -31.80135     -34.662987]
    [-10000.           33.033546     21.409742     20.554382     20.366098
         27.866367     19.72608 ]
    [-10000.           19.434357     31.042831     20.01173      20.029976
         34.242783     26.215023]
    [-10000.           29.454113     31.065586     22.408432     25.096296
         33.43834      24.64881 ]
    [-10000.           15.459914     21.407873     19.595432     29.08403
         27.564583     20.400496]
    [-10000.           22.486092     26.039158     21.080788     20.99098
         26.162144     24.231205]
    [-10000.           15.749684     21.044395     20.90422      19.55778
         27.403168     27.16945 ]
    [-10000.          -30.23591     -34.904922    -29.112244    -33.372574
        -38.870945    -31.372955]
    [-10000.          -36.54284     -36.354404    -31.575878    -37.380985
        -41.379044    -33.561775]
    [-10000.          -33.327114    -34.940624    -26.80739     -34.63032
        -39.341423    -33.110073]
    [-10000.          -35.116844    -37.04653     -30.880705    -34.364735
        -41.586143    -33.566994]
    [-10000.          -39.348537    -41.936092    -35.120056    -36.487373
        -33.76183     -36.38166 ]
    [-10000.          -32.36015     -34.36521     -28.695192    -33.218536
        -37.621857    -29.662157]
    [-10000.           29.933517     16.269938     10.254713     11.976571
         14.170131     14.056596]
    [-1.0000000e+04  1.6334332e+01  2.5903023e+01  9.7120571e+00
      1.1640448e+01  2.0546547e+01  2.0545542e+01]
    [-10000.           11.442712     11.011564 -10000.           14.904465
         18.035984     20.264692]
    [-1.0000000e+04  1.2359885e+01  1.6268066e+01  9.2957649e+00
      2.0694504e+01  1.3868345e+01  1.4731012e+01]
    [-10000.           19.145107     26.751389     22.011566     28.451975
         25.057728     23.772562]
    [-10000.           12.649656     15.904592     10.604551     11.168248
         13.706932     21.499966]
    [-10000.          -41.187008    -39.207726    -34.66185     -44.50358
        -49.27908     -40.43603 ]
    [-10000.          -44.265697    -36.344585    -34.278557    -44.331207
        -46.666218    -39.95015 ]
    [-10000.          -45.59384     -41.10107  -10000.          -45.483444
        -51.778976    -42.13411 ]
    [-10000.          -46.06795     -41.349342    -36.43031     -45.49574
        -51.99427     -42.630066]
    [-10000.          -50.29964     -46.238903    -40.669662    -47.61838
        -44.169956    -45.444733]
    [-10000.          -43.311253    -38.668022    -34.244804    -44.349545
        -48.02999     -38.725227]
    [-1.0000000e+04  1.6326069e+01  8.6766996e+00 -1.0000000e+04
      1.7248930e+00  7.7014732e+00  1.1013615e+01]
    [-1.0000000e+04  9.9429426e+00  2.3916113e+01 -1.0000000e+04
      5.0692425e+00  1.4579213e+01  1.6024635e+01]
    [-1.0000000e+04  1.0167974e+01  1.8408123e+01 -1.0000000e+04
      9.3112278e+00  1.7553471e+01  1.9437597e+01]
    [-1.0000000e+04 -1.2475634e+00  8.6748228e+00 -1.0000000e+04
      1.0442826e+01  7.3996897e+00  1.1688029e+01]
    [-1.0000000e+04  5.5376611e+00  1.9158144e+01 -1.0000000e+04
      1.8200294e+01  1.8589069e+01  2.0729580e+01]
    [-1.0000000e+04 -9.5778799e-01  8.3113508e+00 -1.0000000e+04
      9.1656947e-01  7.2382765e+00  1.8456984e+01]
    [-10000.          -45.088356    -41.389782 -10000.          -47.031803
        -54.202267    -41.660824]
    [-10000.          -48.167038    -38.526646 -10000.          -46.859432
        -51.5894      -41.174946]
    [-10000.          -49.969296    -43.5314   -10000.          -48.02396
        -56.917458    -43.854866]
    [-10000.          -54.200985    -48.420963 -10000.          -50.146606
        -49.093147    -46.669537]
    [-10000.          -44.277237    -38.372986 -10000.          -44.76643
        -51.409805    -40.081924]
    [-1.0000000e+04 -3.9621010e+00 -1.0212009e+01 -1.0000000e+04
     -1.6169300e+01 -1.0070935e+01  7.8766336e+00]
    [-1.0000000e+04 -1.0345229e+01  5.0274076e+00 -1.0000000e+04
     -1.2824954e+01 -3.1931953e+00  1.2887656e+01]
    [-1.0000000e+04 -2.1535732e+01 -1.0213884e+01 -1.0000000e+04
     -7.4513726e+00 -1.0372719e+01  8.5510483e+00]
    [-1.0000000e+04 -1.4750506e+01  2.6943803e-01 -1.0000000e+04
      3.0609548e-01  8.1666344e-01  1.7592600e+01]
    [-1.0000000e+04  5.7635074e+00  1.4409342e+01 -1.0000000e+04
      5.0328212e+00  1.1777478e+01  2.3514055e+01]
    [-10000.          -35.514126    -32.556362 -10000.          -38.506084
        -45.33047     -43.905075]
    [-10000.          -38.592815    -29.69322  -10000.          -38.333714
        -42.71761     -43.4192  ]
    [-10000.          -40.395065    -34.697983 -10000.          -39.498245
        -48.045662    -46.099117]
    [-10000.          -44.62675     -39.58754  -10000.          -41.620884
        -40.221344    -48.91378 ]
    [-10000.          -42.346863    -36.084778 -10000.          -43.860115
        -49.440277    -32.620415]
    [-1.0000000e+04  1.1809083e+01  7.4319105e+00 -1.0000000e+04
     -4.6745052e+00  4.3834662e-01  1.3383590e+01]
    [-1.0000000e+04  1.0129986e+01  2.5822515e+01 -1.0000000e+04
      8.1255350e+00  1.2737367e+01  2.5077654e+01]
    [-1.0000000e+04 -5.7645473e+00  7.4300385e+00 -1.0000000e+04
      4.0434265e+00  1.3656342e-01  1.4058006e+01]
    [-1.0000000e+04  1.0206780e+00  1.7913361e+01 -1.0000000e+04
      1.1800894e+01  1.1325946e+01  2.3099556e+01]
    [-1.00000000e+04  1.01771688e+01  2.15765076e+01 -1.00000000e+04
      7.86213446e+00  1.59928255e+01  1.92248917e+01]
    [-10000.          -47.504322    -38.118187 -10000.          -50.898205
        -55.858696    -23.798182]
    [-10000.          -50.35567     -39.96742  -10000.          -51.925934
        -56.85119     -25.11676 ]
    [-10000.          -52.385265    -40.259804 -10000.          -51.89036
        -58.57389     -25.992214]
    [-10000.          -56.61695     -45.14936  -10000.          -54.01301
        -50.749577    -28.806887]
    [-10000.          -50.975178    -38.22676  -10000.          -49.92742
        -54.507885 -10000.      ]
    [-1.0000000e+04  1.8014664e+01  1.3359744e+01 -1.0000000e+04
      2.7237015e+00  7.5717793e+00 -1.0000000e+04]
    [-10000.           16.335567     31.75034  -10000.           15.523738
         19.8708   -10000.      ]
    [-1.0000000e+04  4.4103098e-01  1.3357874e+01 -1.0000000e+04
      1.1441630e+01  7.2699971e+00 -1.0000000e+04]
    [-1.0000000e+04  7.2262568e+00  2.3841192e+01 -1.0000000e+04
      1.9199099e+01  1.8459377e+01 -1.0000000e+04]
    [-10000.           11.85657      23.091175 -10000.           10.310035
         17.423782 -10000.      ]
    [-10000.          -51.92391     -43.29335  -10000.          -53.8393
        -61.414345 -10000.      ]
    [-10000.          -46.811913    -47.365135 -10000.          -47.53643
        -54.85336  -10000.      ]
    [-10000.          -56.80485     -45.434975 -10000.          -54.831455
        -64.12953  -10000.      ]
    [-10000.          -61.03654     -50.32453  -10000.          -56.954105
        -56.30522  -10000.      ]
    [-1.0000000e+04  1.8692791e+01  1.7086620e+01 -1.0000000e+04
      4.7669907e+00  6.5647211e+00 -1.0000000e+04]
    [-10000.           15.863979     16.15936  -10000.           18.664728
         18.062248 -10000.      ]
    [-1.0000000e+04  1.1191592e+00  1.7084747e+01 -1.0000000e+04
      1.3484922e+01  6.2629380e+00 -1.0000000e+04]
    [-1.0000000e+04  7.9043875e+00  2.7568071e+01 -1.0000000e+04
      2.1242392e+01  1.7452320e+01 -1.0000000e+04]
    [-10000.          -58.443634    -32.94418  -10000.          -59.600388
        -68.54572  -10000.      ]
    [-10000.         -64.60933 -10000.      -10000.         -63.73128
        -70.82022 -10000.     ]
    [-10000.          -63.324574    -35.085796 -10000.          -60.592556
        -71.26092  -10000.      ]
    [-10000.          -67.55626     -39.975357 -10000.          -62.7152
        -63.4366   -10000.      ]
    [-1.0000000e+04  1.9568962e+01 -1.0000000e+04 -1.0000000e+04
      7.9407678e+00  4.1375685e+00 -1.0000000e+04]
    [-10000.            13.410868  -10000.        -10000.
         15.5271015     13.98957   -10000.       ]
    [-1.0000000e+04  1.9953288e+00 -1.0000000e+04 -1.0000000e+04
      1.6658701e+01  3.8357837e+00 -1.0000000e+04]
    [-1.0000000e+04  8.7805548e+00 -1.0000000e+04 -1.0000000e+04
      2.4416168e+01  1.5025168e+01 -1.0000000e+04]
    [-10000.         -69.61724 -10000.      -10000.         -67.57204
        -81.17207 -10000.     ]
    [-10000.          -72.25333  -10000.       -10000.          -67.58594
        -80.555916 -10000.      ]
    [-10000.          -78.72987  -10000.       -10000.          -70.686844
        -76.06295  -10000.      ]
    [-1.0000000e+04  8.1858406e+00 -1.0000000e+04 -1.0000000e+04
      1.0067737e+01 -4.1702042e+00 -1.0000000e+04]
    [-1.0000000e+04 -2.1016173e+00 -1.0000000e+04 -1.0000000e+04
      2.0644901e+01 -2.2050657e+00 -1.0000000e+04]
    [-1.0000000e+04 -2.6025662e+00 -1.0000000e+04 -1.0000000e+04
      2.6543140e+01  6.7173924e+00 -1.0000000e+04]
    [-10000.         -78.0363  -10000.      -10000.         -71.13267
        -87.58725 -10000.     ]
    [-10000.         -75.23989 -10000.      -10000.         -73.76703
        -83.00712 -10000.     ]
    [-10000.          -87.148926 -10000.       -10000.          -74.24748
        -82.478134 -10000.      ]
    [-1.0000000e+04  5.3769606e-01 -1.0000000e+04 -1.0000000e+04
      1.0504855e+01 -1.4138461e+01 -1.0000000e+04]
    [-1.0000000e+04 -7.0657501e+00 -1.0000000e+04 -1.0000000e+04
      1.0317654e+01  2.9839082e+00 -1.0000000e+04]
    [-1.0000000e+04 -1.0250709e+01 -1.0000000e+04 -1.0000000e+04
      2.6980253e+01 -3.2508602e+00 -1.0000000e+04]
    Player 1 Agent...
    Player 2 Agent...
    
    Games Elapsed: 42400
    Current Epsilon: 1.00 percent
    
    Total Training duration: 0.00 mins
    Current Iteration duration: 0.21 seconds
    Estimated Time remaining: 0.00 mins
    


```python
def printStats(interval,memoryCount,epsilon,iterationStartTime,iteration,iterations):
    if iteration % interval == 0:
        print("\nGames Elapsed:",memoryCount)
        print("Current Epsilon:",format(epsilon*100,'.2f'),"percent")
        print("\nTotal Training duration:", format((time.time() - startTime)/60,'.2f'),"minutes")
        print("Current Iteration duration:", format((time.time() - iterationStartTime),'.2f'),"seconds")
        print("Estimated Time remaining:",format((time.time() - iterationStartTime)*(iterations-iteration)/60,'.2f'),"minutes")
```

# Save/Load weights


```python
# Save 'em

network1_json = networks[0].to_json()
with open("network1.json", "w") as json_file:
    json_file.write(network1_json)
networks[0].save_weights("network1.h5")
print("Saved model 1 to disk")

network2_json = networks[1].to_json()
with open("network2.json", "w") as json_file:
    json_file.write(network2_json)
networks[1].save_weights("network2.h5")
print("Saved model 2 to disk")

# SOURCE CODE: https://machinelearningmastery.com/save-load-keras-deep-learning-models/
```

    Saved model 1 to disk
    Saved model 2 to disk
    


```python
# Load 'em

json_file = open('network1.json','r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights("network1.h5")
networks[0] = loaded_model
print("Loaded Model from disk")

json_file = open('network2.json','r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
loaded_model.load_weights("network2.h5")
networks[1] = loaded_model
print("Loaded Model from disk")

# SOURCE CODE: https://machinelearningmastery.com/save-load-keras-deep-learning-models/

networks[0].compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])
networks[1].compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])
```

# TODO
- pick random game random moves independently


```python

```
